这里是扳级程序设计
主要：
1.对于开发板led，button，音频等驱动
2.网络变成连接server，接受server的控制

# 板级程序设计
这里由于自己的驱动了解的还是非常浅薄，所以主要针对应用层进行编码
硬件平台采用imx6ull，其他可以运行linux的平台皆可，但是需要区验证音频（扬声器的驱动）等外设的驱动验证，这里我采用的很多的资料都是基于正点原子的驱动，应用，Qt资料，如果有需要可以自己在docs目录下自取

后面不论是在这一个模块还是其台模块都会分步骤构建整个项目，由于项目整体比较简单，疏漏之处见谅

下面就是基于硬件平台（imx6ull）的一些驱动程序验证

## LED验证

本章内容参考《正点原子imx6ull Linuxc应用编程》
这里呢需要设计到文件系统的一些知识，文件系统知识我自己了解的也是很少，需要大家下去自己多了解，在linux操作系统下的一个概念就是一切皆文件，所以学习linux还是从事和linux相关的职业都绕不开linux内核和文件系统两条路的，最近我自己也在学习这一部分的知识，只是自己学习的很浅薄在这里比方便进行一些没必要的讲解，所以靠自觉啦

*这里关于linux下面外设的设备结点和挂载驱动这方面知识我自己学习的较少，如果大家发现错误还请见谅，及时指出我会更正*

*sysfs文件系统*
sysfs 是一个基于内存的文件系统，同 devfs、proc 文件系统一样，称为虚拟文件系统；它的作用是将内核信息以文件的方式提供给应用层使用
在linux应用层编程中想要控制硬件可以通过`/dev/`下面的目录结点,或者`/sys`目录下面的设备属性文件
在正点原子提供的linux内核和系统镜像中，led可以通过`/sys/class`进行访问

路径
`/sys/class/leds/sys-led`
ls 可以看到sys-led这个就是系统led了，可以通过文件的方式访问硬件资源
进入sys-led目录 ls就可以看到下面的一些关于led的控制方式亮度、电源、触发方式等等
`brightness  device  max_brightness  power  subsystem  trigger  uevent`

shell 方式
```shell
# 点亮led “>” 重定向符号
echo 1 > brightness
# 熄灭led
echo 0 > brightness
```

c语言编程方式
c语言编程方式无疑就是通过文件方式来访问了，通过打开led设备对应的描述文件，通过向文件里面输入不同的内容就可以控制硬件行为
c语言编程方式可见详细源文件
至此控制led已经完成了


## 音频验证

本章内容参考《正点原子imx6ull Linuxc应用编程》
这里是整个项目里面最重要的一点，音频验证涉及到整个项目的逻辑
音频这里就介绍如何录音播放等操作
[参考博客](https://blog.csdn.net/Xinbaibaiya12138/article/details/149325472?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EYuanLiJiHua%7EPosition-2-149325472-blog-133771032.235%5Ev43%5Epc_blog_bottom_relevance_base7&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EYuanLiJiHua%7EPosition-2-149325472-blog-133771032.235%5Ev43%5Epc_blog_bottom_relevance_base7&utm_relevant_index=5)

### ALSA框架概述

ALSA框架是linux下面的高级音频开发子系统，也可以称作为框架。现在Linux系统下的主流音频开发框架就是`ALSA`，ALSA替代了`OSS开发声音系统`，从概述来看ALSA框架我们可以分为三层，从底层到内核空间再到应用空间，分别对应不同的学习体系，例如硬件下需要去学习驱动等，在应用层的话需要熟练使用`alsa-lib`提供的库函数，作为我们编程的基础

![image-20250825230326866](C:\Users\欧鑫\AppData\Roaming\Typora\typora-user-images\image-20250825230326866.png)

在Linux庞大的体系中，除了针对音频开发的`ALSA`框架还需要学习其它框架，例如视频框架`V4L2`和	`ffmpeg`以及音频框架下的`Pipewire`，学习Linux开发，体系过于庞大，需要我们去学习的东西还有很多



### alsa-lib介绍

在我们学习应用层编程最绕不开的就是怎么调用库函数`API`...当然`alsa-lib`就是`ALSA`框架提供的一组编程接口，学习编程接口不需要我们过多的去硬背API的个个参数，理解性学习即可，更多还是要我们去学习框架的概念，架构，培养我们的学习方式

`alsa-lib`是linux提供的一组应用层的c库函数，为音频应用开发提供了一套标准的接口，应用层无需关注底层驱动等实现，只需要我们通过库函数即可实现对硬件设备声卡的驱动实现播放录音等操作

[alsa-lib官方文档地址](https://www.alsa-project.org/alsa-doc/alsa-lib/)

当然啦，如果英文过于晦涩难懂丢给AI也是一份不错的差事，让它生成对应的API参数说明和编程示例效率反而会更高





### sound设备结点

在 `Linux` 内核设备驱动层、基于 `ALSA `音频驱动框架注册的 `sound `设备会在`/dev/snd `目录下生成相应的 设备节点文件，cd到linux的dev目录下，ls即可看到sound对应的设备文件，同理在我们的硬件平台`imx6ull`的shell下也可以查询到对应的设备结点文件

在设备文件夹里面主要由如下内容：

- controlC0**：**用于声卡控制的设备节点，譬如通道选择、混音器、麦克风的控制等，C0 表示声卡 0 （card0）；  
- pcmC0D0c**：**用于录音的 PCM 设备节点。其中 C0 表示 card0，也就是声卡 0；而 D0 表示 device  0，也就是设备 0；最后一个字母 c 是 capture 的缩写，表示录音；所以 pcmC0D0c 便是系统的声卡 0 中的录音设备 0；  
- pcmC0D0p**：**用于播放（或叫放音、回放）的 PCM 设备节点。其中 C0 表示 card0，也就是声卡 0； 而 D0 表示 device 0，也就是设备 0；最后一个字母 p 是 playback 的缩写，表示播放；所以 pcmC0D0p 便是系统的声卡 0 中的播放设备 0；  
- pcmC0D1c**：**用于录音的 PCM 设备节点。对应系统的声卡 0 中的录音设备 1； 
- pcmC0D1p**：**用于播放的 PCM 设备节点。对应系统的声卡 0 中的播放设备 1；
- timer**：**定时器

其中在我的ubuntu下面特有一个seq文件，seq是ALSA的序列器，可以为应用程序之间提供基于时间和序列的高精度MIDI（Musical Instrument Digital Interface - 音乐设备数字接口）保证数据和事件的路由与调度

我们操作Linux下面的任何硬件设备都是通过操作文件的方式来控制（因为在Linux系统下一切设备皆为文件的概念），所以在应用层抽象成文件io的方式来操作设备结点里面的文件让我们无需去关注底层的驱动实现即可操作硬件

在linux系统下的`/proc/asound`目录下面，存在很多文件，它们描述了系统的声卡等信息

​	**cards**文件

cards文件里面描述了系统中可用的、注册的声卡



​	**devices**文件

devices文件描述了系统中所有声卡注册的设备，包括 control、pcm、timer、seq 等等



​	**PCM**

pcm文件描述了系统可用的pcm设备

```
在linux系统下面可以使用cat来查看这些设备信息
```



### alsa工具集使用



​	**aplay工具**

aplay工具用来播放音频等操作，这里可以类比ffmpeg里面的`ffplay`操作同样都是播放音频；aplay可以播放wav格式文件，不支持MP3格式文件，而ffmpeg工具中的ffplay就强大很多

​	**alsamixer工具**

用来配置声卡信息的工具，例如音量等

​	**alsactl工具**

用来保存声卡的配置信息，因为我们配置完毕声卡信息之后不保存，重启后声卡又恢复默认配置了

​	**amixer**

也是一个声卡信息配置工具，与alsamixer的区别是它是一个字符型的配置工具

​	**arecord**

是一个用于录音测试的工具

```c
arecord -f cd -d 10 test.wav // 录音十秒
```





至此alsa框架的简单介绍完毕了，后面会采用c语言的方式来学习和使用asla-lib，在学习过程中可能仅会针对自己在整个项目中需要使用到的一些函数去使用和学习，更多的内容还是需要自己去拓展吖



### alsa-libc编程

hello吖，在这里我们就要基于`ALSA`音频开发框架去进行应用编程了，这里呢还是要在简单的`alsa-lib`库学习完毕之后，去了解一下`ALSA`框架里面得其它内容呢，毕竟这个项目打算制作在简历里面，一些非常有必要的深度学习还是很重要得

学习音视频或者嵌入式linux与音视频开发绕不开的方向就是音频开发框架`ALSA`视频开发框架`ffmpeg`等，所以在积累到一定经验的时候去深入学习相关内容，这样才能在后面的个人发展上取得更好的竞争力





### alsa-lib音频应用编程

这里呢因为我时间的缘故，也是为了尽快做完项目去秋招的原因，对`alsa-lib`的学习不会太深入，提供非常简单的基础示例学习和参考，如果你时间足够充裕，把`ALSA`框架整体学习完毕还是非常不错的选择，在linux开发中，我们无法绕开这些内容，既然无法逃避，直面他吧，让它成为我成功的一部分（今天心情好推荐一首音乐：Try）



这里展示两个`ALSA`提供的参考手册

[ALSA提供的库使用示例](https://users.suse.com/~mana/alsa090_howto.html)

[示例代码](https://www.alsa-project.org/alsa-doc/alsa-lib/examples.html)



**基础知识介绍**

**样本长度（位深度）：**如果直接说样本长度可能大家还不清楚这是什么意思，如果说位深度是不是有点点耳熟呢，没错哦，在音视频变成里面无法避开位深度这个概念的；而位深度代表我们存储一个采用信号所用的位（8位 = 1字节）如果说就和一个像素点一样呢，有没有很熟悉了。通常在我们采用越高的位深度的情况下，采集的数据是会被越准确表示的（这里换算一下压缩算法，牺牲数据换取空间），后面更多称之为位深度



**声道数：**声道数这个概念大家肯定会很熟悉的，比如我们听音乐时可以选择（立体环绕音，当然啦这是要开vip才能有的待遇）多声道等播放形式



**帧：**一个帧记录一个声音单元，帧大小（位深度*声道数），例如一个24位深度，双声道的的一帧数据大小为（24 * 2 /8）=6字节



**采样率：**采样率也可以称作为采样频率，这个概念相对于一帧而言，比如我们1HZ的采样频率下就一秒钟采样一次，对于高音质而言，我们的采样频率越高越能模拟当时的场景（声音）



**交错模式：**交错模式是一种音频数据的记录方式，分为交错模式和非交错模式。在交错模式下，数据以连续桢的形 式存放，即首先记录完桢 1 的左声道样本和右声道样本（假设为立体声格式），再记录桢 2 的左声道样本和 右声道样本。而在非交错模式下，首先记录的是一个周期内所有桢的左声道样本，再记录右声道样本，数据 是以连续通道的方式存储。不过多数情况下，我们一般都是使用交错模式



**周期：**周期是音频设备处理（读、写）数据的单位，换句话说，也就是音频设备读写数据的单位是周期，每一 次读或写一个周期的数据，一个周期包含若干个帧；譬如周期的大小为 1024 帧，则表示音频设备进行一次 读或写操作的数据量大小为 1024 帧



**缓冲区（buffer）：**看着这个有没有想起写环形队列的时候的环形buff了，没错就是这种概念，只不过这里面的缓冲器存储的数据单元是按照周期来计算的，比如存储4的周期的数据，一个周期1024（为什么1024，可能是对2进制敏感一点）帧，一帧数据=位深度（24）*声道数（2），聪明的你有没有算出来总的字节数呢？（4 * 1024 * 24 * 2 /8）= 24kb



**DMA（直接内存访问）：**如果大家学习了嵌入式那么对于这个dma肯定很熟悉了吧，当我们学习音视频开发通常传输数据量都是非常大的，这个时候不想让cpu的效率很低，那么首选就是dma了，一个dma又分为多通道（哈哈哈说到这里经常在公司听到他们说通道，现在也是恍然大悟），这样来说加入了dma控制器让我们在视频传输上性能会有很大的提升



**音频底层传输：**音频设备底层驱动程序使用 DMA 来搬运数据，这个 buffer 中有 4 个 period，每当 DMA 搬运完一个 period 的数据就会触发一次中断，因此搬运整个 buffer 中的数据将产生 4 次中断。ALSA 为什么这样做？直接把整个 buffer 中的数据一次性搬运过去岂不是更快？情况并非如此，我们没有考虑到一个很重要的问题， 那就是延迟；如果数据缓存区 buffer 很大，一次传输整个 buffer 中的数据可能会导致不可接受的延迟，因为 一次搬运的数据量越大，所花费的时间就越长，那么必然会导致数据从传输开始到发出声音（以播放为例） 这个过程所经历的时间就会越长，这就是延迟。为了解决这个问题，**ALSA 把缓存区拆分成多个周期**，以周 期为传输单元进行传输数据。  所以，周期不宜设置过大，周期过大会导致延迟过高；但周期也不能太小，周期太小会导致频繁触发中 断，这样会使得 CPU 被频繁中断而无法执行其它的任务，使得效率降低！所以，周期大小要合适，在延迟 可接受的情况下，尽量设置大一些，不过这个需要根据实际应用场合而定，有些应用场合，可能要求低延迟、 实时性高的话像是我们进行实时流传输（RTSP）等，就更加需要考量周期的设计



**数据传输场景：**

播放：这里在我之前提到过的环形buff有没有想起来，没错，一边想缓冲区写数据，音频设备通过dma来读取我们的数据，这样他就可以拿到数据进行播放了，如果这个时候一个周期内的数据很大就造成了延时大；

录音：同样的在录音情况下，提前预留缓冲区交互，音频设备通过adc将物理信号转换成为数字信号（二进制数据）写入缓冲区中，我们这边去读缓冲区数据，然后写入文件保存。这样交互我们得到的是原生数据信息。如果在整个数据加上对应的帧头帧尾呢，这样是不是就得到了我们熟悉的数据格式了比如mp3之类的数据格式，都是经过数据格式的封装





### 音频编程实战

这里就会进行示例编程了，利用`alsa-lib`提供的库，进行音频应用编程，可以制作简单的音频播放器。在我们的项目中，实现最简单的音频播放就可以了这个是最简单的交互逻辑了，当然一个项目应该具有更加完善完美的逻辑了，这里我们也只是将核心功能最小化，后面我们可以根据自己对项目的理解扩充其它更加广阔的内容和知识



hello吖，现在开始需要我们使用`alsalib`来控制播放音频等操作了，在linux上一切皆文件，所以对于linux的io操作，io复用，select，poll，epoll，以及多线程多进程都是需要很好的理解的

下面对一些常见的API进行简单的使用示例



#### **1.打开PCM设备**

```c
int snd_pcm_open(snd_pcm_t **pcmp, const char *name, snd_pcm_stream_t stream, int mode) ;
```

- pcmp**：**snd_pcm_t 用于描述一个 PCM 设备，所以一个 snd_pcm_t 对象表示一个 PCM 设备； snd_pcm_open 函数会打开参数 name 所指定的设备，实例化 snd_pcm_t 对象，并将对象的指针（也 就是 PCM 设备的句柄）通过 pcmp 返回出来。  
- name**：**参数 name 指定 PCM 设备的名字。alsa-lib 库函数中使用逻辑设备名而不是设备文件名，命 名方式为"hw:i,j"，i 表示声卡的卡号，j 则表示这块声卡上的设备号；譬如"hw:0,0"表示声卡 0 上的 PCM 设备 0，在播放情况下，这其实就对应/dev/snd/pcmC0D0p（如果是录音，则对应 /dev/snd/pcmC0D0c）。除了使用"hw:i,j"这种方式命名之外，还有其它两种常用的命名方式，譬如 "plughw:i,j"、"default"等，关于这些名字的不同，本章最后再向大家进行简单地介绍，这里暂时先 不去理会这个问题。 
-  stream**：**参数 stream 指定流类型，有两种不同类型：SND_PCM_STREAM_PLAYBACK 和 SND_PCM_STREAM_CAPTURE ； SND_PCM_STREAM_PLAYBACK 表 示 播 放 ， SND_PCM_STREAM_CAPTURE 则表示采集。 
-  mode**：**最后一个参数 mode 指定了 open 模式，通常情况下，我们会将其设置为 0，表示默认打开 模式，默认情况下使用阻塞方式打开设备；当然，也可将其设置为 SND_PCM_NONBLOCK，表示 以非阻塞方式打开设备。

```c
int snd_pcm_close(snd_pcm_t);// 与之对应的就是关闭操作
```



设备打开成功返回0，失败返回一个小于0的错误编号



**编程示例**

```c
struct snd_pcm_t *pcm_handle =NULL;//定义一个snd_pcm_t类型指针，等待open函数成功的话就可以使用指针操作设备
int ret; 
 
ret = snd_pcm_open(&pcm_handle, "hw:0,0", SND_PCM_STREAM_PLAYBACK, 0); 
if (0 > ret) { 
 fprintf(stderr, "snd_pcm_open error: %s\n", snd_strerror(ret)); 
 return -1; 
}
```



#### 2.设置参数

我们打开了设备之后，设备还是无法正常工作的，我们需要对齐进行参数配置，主要是对硬件参数进行配置，譬如**采样率**、**声道数**、格式、**访问类型**、**period 周期大小**、**buffer 大小**等。 

采样率：一秒内样本采样多少次 比如44.1KHZ （一秒内采样 44.1k次），这样采集下来的大小称为一帧

声道数：多声道还是单声道

周期大小：就是一个周期内包含多少帧数据

缓冲区（buff）大小：通常用周期大小作为基数

周期数：缓冲区大小被划分为多少帧



**实例化snd_pcm_params对象**

在进行设置参数时，我们同样需要使用一个hw结构体指针来实例化一个对象

```c
// 这里可以从结构体名称很清楚的了解到这个结构体的作用
snd_pcm_hw_params_t *hwparams = NULL; 
 
snd_pcm_hw_params_malloc(&hwparams); 
//这里两种写法都可以，具体的话malloc和alloc可以去了解一下Linux系统的内存管理会有一个初步了解
snd_pcm_hw_params_alloca(&hwparams); 
```



**释放snd_pcm_params对象**

```c
void snd_pcm_hw_params_free(snd_pcm_hw_params_t *obj) ;
```



**设置PCM参数**

上面的操作无异于就是我们对一个`snd_pcm_hw_params_t` 对象进行了一个实例化，需要设置参数进去

```c
// 设置参数进去 
void snd_pcm_hw_params_any(pcm_handle,hwparams);
snd_pcm_hw_params_any(pcm_handle, hwparams); 
```

这是一个统一接口，alsa-lib还提供了其它单一参数设置接口

```c
snd_pcm_hw_params_set_xxx //这是对应的函数 _xxx就是我们需要设置的参数
```

例如我们设置access访问类型参数，其它的参数同样的都是见名知意

```c
snd_pcm_hw_params_set_access() 
```

剩下对应的接口无疑就是对`snd_pcm_hw_params_t`结构体里面的参数进行了一个单独设置获取的操作



#### 3.读写数据

在这里了，我们前面做了什么？分别是打开设备，设置参数，参数设置完毕之后就是我们操作PCM设备了，我们向PCM设备写数据就是驱动它播放音乐，读数据就是驱动采集

这里呢，就对两个操作进行了单独的封装，函数原型如下

```c
// snd_pcm_sframes_t 
// pcm 对应的描述设备
// buffer 应用程序的缓冲区就是和pcm设备的数据交互缓冲区
// size 指定写入数据大小，帧为单位
snd_pcm_sframes_t snd_pcm_writei(snd_pcm_t *pcm, 
 const void *buffer, 
 snd_pcm_uframes_t size 
) 
 
snd_pcm_sframes_t snd_pcm_readi(snd_pcm_t *pcm, 
 void *buffer, 
 snd_pcm_uframes_t size 
) 
```



**阻塞读写和非阻塞读写**

当我们调用`snd_pcm_open`打开设备时，可以设置读写模式（阻塞、非阻塞）

阻塞读写：当缓冲区里面数据满（空）的时候，调用读写函数时会阻塞，等待缓冲区有数据（可写）的时候在进行写入

非阻塞读写：就是调用读写函数的时候，发生上面的场景会直接返回错误码退出而不阻塞



#### 4.播放音频
在自己的另一个仓库Linux-System中实现了ALSA的音频框架编程
ALSA框架只支持PCM音频格式，wav就是44字节报头+PCM原生数据
的格式，通过在wav报头里面拿到通道数和采样率即可实现播放操作



#### 5.录制音频
录制音频操作就是封装一个wav文件头，然后写入PCM原始数据即可，
然后回填部分字段信息

















#### **内存管理经验**

与之对应的就是内存空间的回收了，在我参加的项目当中，就是因为上一位程序员对内存管理的疏忽导致整个项目能跑起来但是非常”怪“，如果把指针置空我们可以进行`if(NULL != ptr) 或者 assert(ptr!=NULL) `等提前预防空指针的操作，但是野指针呢，如果你的指针乱指，整个程序就会造成莫名奇妙的情况，所以作为一名合格的c/c++、嵌入式程序员对内存的管理必须严谨。

然而在内存管理方面C++又是比C语言更加方便的，因为C++语言的面向对象特性，我们不论是使用`RAII`机制，还是智能指针来管理对象，都可以对内存管理做一个很好的管理，对比于C语言我们的每个`malloc`都需要我们自己去`free`所以大家在c编程时一定要对内存敏感




## 并发和网络编程设计

在现在的服务模型中，只有UI和应用交互称作离线操作，也就是我后面需要加上的UI界面，当然拉，其实有一个很重要的问题就是它们通过socket通信，大家可能认为这不是离线操作，这里指的离线操作呢是客户端可以连接上服务器，向服务器请求实时流可以推到应用上来播放，自己现在考虑的模型呢也很简单，ui和应用交互操作不难，难的是服务器设计，以及怎么处理服务器的并发操作，后面会对网络编程的概念进行一个简要的梳理，以及处理复用时我们怎么做等等...




